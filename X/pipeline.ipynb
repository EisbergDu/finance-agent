{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d7e7a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import http.client\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83a18f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TheEconomist',\n",
       " 'Reuters',\n",
       " 'WSJ',\n",
       " 'Forbes',\n",
       " 'business',\n",
       " 'business',\n",
       " 'FinancialTimes',\n",
       " 'FT',\n",
       " 'CNBC',\n",
       " 'CNBC',\n",
       " 'BusinessInsider',\n",
       " 'FortuneMagazine',\n",
       " 'ZeroHedge',\n",
       " 'unusual_whales',\n",
       " 'YahooFinance',\n",
       " 'BillAckman',\n",
       " 'TheRoaringKitty',\n",
       " 'WallStreetSilv',\n",
       " 'michaeljburry',\n",
       " 'StockTwits',\n",
       " 'themotleyfool',\n",
       " 'TheStreet',\n",
       " 'stlouisfed',\n",
       " 'DeItaone',\n",
       " 'TaraBull808',\n",
       " 'Carl_C_Icahn',\n",
       " 'ParikPatelCFA',\n",
       " 'PelosiTracker_',\n",
       " 'charliebilello',\n",
       " 'PeterLBrandt',\n",
       " 'StockMKTNewz',\n",
       " 'RaoulGMI',\n",
       " 'gurgavin',\n",
       " 'FinancialReview',\n",
       " 'morganhousel',\n",
       " 'IBDinvestors',\n",
       " 'barronsonline',\n",
       " 'WOLF_Financial',\n",
       " 'Benzinga',\n",
       " 'FXStreetNews',\n",
       " 'Jake__Wujastyk',\n",
       " 'SeekingAlpha',\n",
       " 'LynAldenContact',\n",
       " 'TradesTrey',\n",
       " 'AswathDamodaran',\n",
       " 'LynAldenContact',\n",
       " 'MorningStarInc',\n",
       " 'allstarcharts',\n",
       " 'matt_levine',\n",
       " 'WallStCynic',\n",
       " 'BarChart',\n",
       " 'ReformedBroker',\n",
       " 'QuiverQuant',\n",
       " 'michaelbatnick',\n",
       " 'TruthGundlach',\n",
       " 'litcapital',\n",
       " 'ritholtz',\n",
       " 'DoombergT',\n",
       " 'EpsilonTheory',\n",
       " 'fundstrat',\n",
       " 'TheStalwart',\n",
       " 'zachxbt',\n",
       " 'CramerTracker',\n",
       " 'LizAnnSonders',\n",
       " 'dougboneparth',\n",
       " 'jposhaughnessy',\n",
       " 'TikTokInvestors',\n",
       " 'nasdaq',\n",
       " 'BrianFeroldi',\n",
       " 'jasonzweigwsj',\n",
       " 'MarkYusko',\n",
       " 'RyanDetrick',\n",
       " 'Stephanie_Link',\n",
       " 'wolfejosh',\n",
       " 'Cokedupoptions',\n",
       " 'SallieKrawcheck',\n",
       " 'StockJabber',\n",
       " 'FinancialPost',\n",
       " 'awealthofcs',\n",
       " 'GRDecter',\n",
       " 'BuccoCapital',\n",
       " 'alifarhat79',\n",
       " 'howardlindzon',\n",
       " 'masked_investor',\n",
       " 'MichaelKitces',\n",
       " 'VCBrags',\n",
       " 'LastBearStanding',\n",
       " 'leadlagreport',\n",
       " 'SamRo',\n",
       " 'sentimentrader',\n",
       " 'stocktalkweekly',\n",
       " 'jessefelder',\n",
       " 'SteadyCompound',\n",
       " 'cullenroche',\n",
       " 'EricBalchunas',\n",
       " 'garyblack00',\n",
       " 'hmeisler',\n",
       " 'jmackin2',\n",
       " 'EddyElfenbein',\n",
       " 'TheTranscript_',\n",
       " 'jackschwager',\n",
       " 'KathyJones',\n",
       " 'kylascan',\n",
       " 'markminervini',\n",
       " 'RampCapitalLLC',\n",
       " 'RedDogT3',\n",
       " 'Kiplinger',\n",
       " 'aclenow',\n",
       " 'mark_dow',\n",
       " 'AdamMancini4',\n",
       " 'EconguyRosie',\n",
       " 'EdgeCGroup',\n",
       " 'iancassel',\n",
       " 'Jesse_Livermore',\n",
       " 'MacroAlf',\n",
       " 'ruima',\n",
       " 'SamanthaLaDuc',\n",
       " 'TaviCosta',\n",
       " 'tseides',\n",
       " 'AlphaGammaHQ',\n",
       " 'AndreasSteno',\n",
       " 'AndrewThrasher',\n",
       " 'MorganCreek_Dig',\n",
       " 'smartasset',\n",
       " 'dailydirtnap',\n",
       " 'DividendGrowth',\n",
       " 'DKellerCMT',\n",
       " 'InvestorAmnesia',\n",
       " 'LizYoungStrat',\n",
       " 'NateGeraci',\n",
       " 'ppearlman',\n",
       " 'TSOH_Investing',\n",
       " 'Dividendology',\n",
       " 'DavidKass3',\n",
       " 'irbezek',\n",
       " 'JulianMI2',\n",
       " 'kevinmuir',\n",
       " 'Ksidiii',\n",
       " 'PriapusIQ',\n",
       " 'profplum99',\n",
       " 'TihoBrkan',\n",
       " 'BullishRippers',\n",
       " 'EconomPic',\n",
       " 'JulianKlymochko',\n",
       " 'KrisAbdelmessih',\n",
       " 'quakes99',\n",
       " 'sinstockpapi',\n",
       " 'TheSpeculator0',\n",
       " 'tolstoybb',\n",
       " 'ukarlewitz',\n",
       " 'amlivemon',\n",
       " 'AnalystDC',\n",
       " 'ContrarianShort',\n",
       " 'CullenFrost',\n",
       " 'GlobalStockPick',\n",
       " 'hkuppy',\n",
       " 'macrocephalopod',\n",
       " 'Post_Market',\n",
       " 'ZacksResearch',\n",
       " 'SwaggyStocks',\n",
       " 'CasinoCapital',\n",
       " 'Chariot_Invest',\n",
       " 'DataDInvesting',\n",
       " 'DV_Situations',\n",
       " 'Gold_Mansack',\n",
       " 'HolyFinance',\n",
       " 'insiliconot',\n",
       " 'JaySinh130',\n",
       " 'jedimarkus77',\n",
       " 'JerryCap',\n",
       " 'JTSEO9',\n",
       " 'MacroTactical',\n",
       " 'masterly_in',\n",
       " 'MichaelGoodwell',\n",
       " 'orthereaboot',\n",
       " 'PandaValue',\n",
       " 'PythiaR',\n",
       " 'ResGloStocks',\n",
       " 'ReturnsJourney',\n",
       " 'Ross_Report',\n",
       " 'SardonicCanuck',\n",
       " 'SrivatsPrakash',\n",
       " 'StocksOnSpaces',\n",
       " 'therobotjames',\n",
       " 'ValueStockGeek',\n",
       " 'thebalance',\n",
       " 'MarketBeatCon',\n",
       " 'Biohazard3737',\n",
       " 'breadcrumbsre',\n",
       " 'darjohn25',\n",
       " 'dirtcheapstocks',\n",
       " 'DonutShorts',\n",
       " 'ValueSotp',\n",
       " 'GuruFocus',\n",
       " 'austinhankwitz',\n",
       " 'ComposerTrade',\n",
       " 'HudsonLabs',\n",
       " 'UptrendsAI',\n",
       " 'SmallCapWhales']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 读取美股kol_list\n",
    "a_kol_df = pd.read_excel('a_kol.xlsx')\n",
    "a_kol_df.head(5)\n",
    "a_kol_list = a_kol_df['Twitter Handle'].tolist()\n",
    "a_kol_list = [account.lstrip('@') for account in a_kol_list]\n",
    "a_kol_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf1940c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_user_rest_id(user_name):\n",
    "    conn = http.client.HTTPSConnection(\"api.apidance.pro\")\n",
    "    payload = ''\n",
    "    headers = {\n",
    "    'apikey': 'q4fa83ok43io70najdgmijdt2s6fkl'\n",
    "    }\n",
    "    conn.request(\"GET\", f\"/graphql/UserByScreenName?variables=%7B%22screen_name%22:%22{user_name}%22,%22withSafetyModeUserFields%22:true,%22withHighlightedLabel%22:true%7D\", payload, headers)\n",
    "    res = conn.getresponse()\n",
    "    data = res.read()\n",
    "    json_data = json.loads(data.decode(\"utf-8\"))\n",
    "    rest_id = json_data['data']['user']['result']['rest_id']\n",
    "    return rest_id \n",
    "\n",
    "def get_user_tweets_page(user_id, cursor=None):\n",
    "    \"\"\"获取单页用户推文\"\"\"\n",
    "    conn = http.client.HTTPSConnection(\"api.apidance.pro\")\n",
    "    headers = {\n",
    "       'apikey': 'q4fa83ok43io70najdgmijdt2s6fkl'\n",
    "    }\n",
    "    \n",
    "    # 构建URL\n",
    "    url = f\"/sapi/UserTweets?user_id={user_id}\"\n",
    "    if cursor:\n",
    "        url += f\"&cursor={cursor}\"\n",
    "    else:\n",
    "        url += \"&cursor=null\"\n",
    "    \n",
    "    conn.request(\"GET\", url, '', headers)\n",
    "    res = conn.getresponse()\n",
    "    data = res.read()\n",
    "    return json.loads(data.decode(\"utf-8\"))\n",
    "\n",
    "\n",
    "def fetch_user_tweets(user_id, max_pages=10, save_to_file=True, filename=None):\n",
    "    \"\"\"\n",
    "    获取用户的多页推文\n",
    "    \n",
    "    参数:\n",
    "        user_id (str): Twitter用户ID\n",
    "        max_pages (int): 最多获取的页数，默认10页\n",
    "        save_to_file (bool): 是否保存到文件，默认True\n",
    "        filename (str): 保存的文件名，默认为 'tweets_{user_id}.json'\n",
    "    \n",
    "    返回:\n",
    "        list: 所有推文的列表\n",
    "    \"\"\"\n",
    "    all_tweets = []\n",
    "    cursor = None\n",
    "    page = 1\n",
    "    \n",
    "    print(f\"\\n开始获取用户 {user_id} 的推文...\")\n",
    "    print(f\"最多获取 {max_pages} 页\\n\")\n",
    "    \n",
    "    while page <= max_pages:\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"正在获取第 {page} 页...\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        try:\n",
    "            # 获取当前页\n",
    "            response = get_user_tweets_page(user_id, cursor)\n",
    "            \n",
    "            # 提取推文\n",
    "            tweets = response.get('tweets', [])\n",
    "            all_tweets.extend(tweets)\n",
    "            \n",
    "            print(f\"✓ 本页获取 {len(tweets)} 条推文\")\n",
    "            print(f\"✓ 累计获取 {len(all_tweets)} 条推文\")\n",
    "            \n",
    "            # 获取下一页游标\n",
    "            next_cursor = response.get('next_cursor_str')\n",
    "            \n",
    "            if not next_cursor:\n",
    "                print(\"\\n✓ 没有更多推文了\")\n",
    "                break\n",
    "            \n",
    "            print(f\"✓ 下一页游标: {next_cursor[:50]}...\")\n",
    "            \n",
    "            cursor = next_cursor\n",
    "            page += 1\n",
    "            \n",
    "            # 暂停1秒，避免请求过快\n",
    "            # if page <= max_pages:\n",
    "            #     time.sleep(1)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"\\n✗ 获取第 {page} 页时出错: {str(e)}\")\n",
    "            break\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"总共获取 {len(all_tweets)} 条推文\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # # 保存到文件\n",
    "    # if save_to_file:\n",
    "    #     if filename is None:\n",
    "    #         filename = f'tweets_{user_id}.json'\n",
    "        \n",
    "    #     with open(filename, 'w', encoding='utf-8') as f:\n",
    "    #         json.dump(all_tweets, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "    #     print(f\"✓ 推文已保存到 {filename}\")\n",
    "    \n",
    "    return all_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd67ca55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TheEconomist',\n",
       " 'Reuters',\n",
       " 'WSJ',\n",
       " 'Forbes',\n",
       " 'business',\n",
       " 'business',\n",
       " 'FinancialTimes',\n",
       " 'FT',\n",
       " 'CNBC',\n",
       " 'CNBC']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_kol_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e55dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "开始获取用户 5988062 的推文...\n",
      "最多获取 20 页\n",
      "\n",
      "============================================================\n",
      "正在获取第 1 页...\n",
      "============================================================\n",
      "✓ 本页获取 20 条推文\n",
      "✓ 累计获取 20 条推文\n",
      "✓ 下一页游标: DAAHCgABG52eIDE__-oLAAIAAAATMTk4OTgzMDg4NTAzODg0Nj...\n",
      "============================================================\n",
      "正在获取第 2 页...\n",
      "============================================================\n",
      "✓ 本页获取 20 条推文\n",
      "✓ 累计获取 40 条推文\n",
      "✓ 下一页游标: DAAHCgABG52eIDE__9ULAAIAAAATMTk4OTczMzkwMzk2ODM5OT...\n",
      "============================================================\n",
      "正在获取第 3 页...\n",
      "============================================================\n",
      "✓ 本页获取 20 条推文\n",
      "✓ 累计获取 60 条推文\n",
      "✓ 下一页游标: DAAHCgABG52eIDE__8ALAAIAAAATMTk4OTY1NDYzNzMwNjE3MT...\n",
      "============================================================\n",
      "正在获取第 4 页...\n",
      "============================================================\n",
      "✓ 本页获取 20 条推文\n",
      "✓ 累计获取 80 条推文\n",
      "✓ 下一页游标: DAAHCgABG52eIDE__6sLAAIAAAATMTk4OTU1OTA5NjM0NTgyNT...\n",
      "============================================================\n",
      "正在获取第 5 页...\n",
      "============================================================\n",
      "✓ 本页获取 20 条推文\n",
      "✓ 累计获取 100 条推文\n",
      "✓ 下一页游标: DAAHCgABG52eIDE__5YLAAIAAAATMTk4OTQ1ODM0ODExMDk0Mj...\n",
      "============================================================\n",
      "正在获取第 6 页...\n",
      "============================================================\n",
      "✓ 本页获取 20 条推文\n",
      "✓ 累计获取 120 条推文\n",
      "✓ 下一页游标: DAAHCgABG52eIDE__4ELAAIAAAATMTk4OTM5OTIwNzk5MjU3OD...\n",
      "============================================================\n",
      "正在获取第 7 页...\n",
      "============================================================\n",
      "✓ 本页获取 20 条推文\n",
      "✓ 累计获取 140 条推文\n",
      "✓ 下一页游标: DAAHCgABG52eIDE__2wLAAIAAAATMTk4OTM1NTIwNTY3OTMwND...\n",
      "============================================================\n",
      "正在获取第 8 页...\n",
      "============================================================\n",
      "✓ 本页获取 20 条推文\n",
      "✓ 累计获取 160 条推文\n",
      "✓ 下一页游标: DAAHCgABG52eIDE__1cLAAIAAAATMTk4OTI4MjE4MTc5ODA0MD...\n",
      "============================================================\n",
      "正在获取第 9 页...\n",
      "============================================================\n",
      "✓ 本页获取 19 条推文\n",
      "✓ 累计获取 179 条推文\n",
      "✓ 下一页游标: DAAHCgABG52eIDE__0MLAAIAAAATMTk4OTE5MTU5Mjk3NzAxND...\n",
      "============================================================\n",
      "正在获取第 10 页...\n",
      "============================================================\n",
      "✓ 本页获取 20 条推文\n",
      "✓ 累计获取 199 条推文\n",
      "✓ 下一页游标: DAAHCgABG52eIDE__y4LAAIAAAATMTk4OTA5NTk1OTc0MjAxNz...\n",
      "============================================================\n",
      "正在获取第 11 页...\n",
      "============================================================\n",
      "✓ 本页获取 20 条推文\n",
      "✓ 累计获取 219 条推文\n",
      "✓ 下一页游标: DAAHCgABG52eIDE__xkLAAIAAAATMTk4OTA0ODEzOTQ2Mjk4ND...\n",
      "============================================================\n",
      "正在获取第 12 页...\n",
      "============================================================\n",
      "✓ 本页获取 20 条推文\n",
      "✓ 累计获取 239 条推文\n",
      "✓ 下一页游标: DAAHCgABG52eIDE__wQLAAIAAAATMTk4OTAyMzAxNTE1MDAwMj...\n",
      "============================================================\n",
      "正在获取第 13 页...\n",
      "============================================================\n",
      "✓ 本页获取 20 条推文\n",
      "✓ 累计获取 259 条推文\n",
      "✓ 下一页游标: DAAHCgABG52eIDE__u8LAAIAAAATMTk4ODk5NzE2MDc4OTA2Nj...\n",
      "============================================================\n",
      "正在获取第 14 页...\n",
      "============================================================\n",
      "✓ 本页获取 20 条推文\n",
      "✓ 累计获取 279 条推文\n",
      "✓ 下一页游标: DAAHCgABG52eIDE__toLAAIAAAATMTk4ODk1MDAwNDg0NTc1Mj...\n",
      "============================================================\n",
      "正在获取第 15 页...\n",
      "============================================================\n",
      "✓ 本页获取 20 条推文\n",
      "✓ 累计获取 299 条推文\n",
      "✓ 下一页游标: DAAHCgABG52eIDE__sULAAIAAAATMTk4ODg5OTY2MjgwODQ1Mz...\n",
      "============================================================\n",
      "正在获取第 16 页...\n",
      "============================================================\n",
      "✓ 本页获取 20 条推文\n",
      "✓ 累计获取 319 条推文\n",
      "✓ 下一页游标: DAAHCgABG52eIDE__rALAAIAAAATMTk4ODgwNDE1MTE5OTg1NT...\n",
      "============================================================\n",
      "正在获取第 17 页...\n",
      "============================================================\n",
      "✓ 本页获取 20 条推文\n",
      "✓ 累计获取 339 条推文\n",
      "✓ 下一页游标: DAAHCgABG52eIDE__psLAAIAAAATMTk4ODcxMzQ3MDcxNjQyOD...\n",
      "============================================================\n",
      "正在获取第 18 页...\n",
      "============================================================\n",
      "✓ 本页获取 20 条推文\n",
      "✓ 累计获取 359 条推文\n",
      "✓ 下一页游标: DAAHCgABG52eIDE__oYLAAIAAAATMTk4ODY0OTI2Mjc3MTU0OD...\n",
      "============================================================\n",
      "正在获取第 19 页...\n",
      "============================================================\n",
      "✓ 本页获取 20 条推文\n",
      "✓ 累计获取 379 条推文\n",
      "✓ 下一页游标: DAAHCgABG52eIDE__nELAAIAAAATMTk4ODU4NzU5NDc3MTIxND...\n",
      "============================================================\n",
      "正在获取第 20 页...\n",
      "============================================================\n",
      "✓ 本页获取 20 条推文\n",
      "✓ 累计获取 399 条推文\n",
      "✓ 下一页游标: DAAHCgABG52eIDE__lwLAAIAAAATMTk4ODU0ODY4MjA0MDM5MD...\n",
      "\n",
      "============================================================\n",
      "总共获取 399 条推文\n",
      "============================================================\n",
      "\n",
      "开始获取用户 1652541 的推文...\n",
      "最多获取 20 页\n",
      "\n",
      "============================================================\n",
      "正在获取第 1 页...\n",
      "============================================================\n",
      "✓ 本页获取 20 条推文\n",
      "✓ 累计获取 20 条推文\n",
      "✓ 下一页游标: DAAHCgABG52efAb__-sLAAIAAAATMTk4OTg4NjE2ODM4NTYxND...\n",
      "============================================================\n",
      "正在获取第 2 页...\n",
      "============================================================\n",
      "✓ 本页获取 20 条推文\n",
      "✓ 累计获取 40 条推文\n",
      "✓ 下一页游标: DAAHCgABG52efAb__9cLAAIAAAATMTk4OTg0MDg3NTk2MzIyND...\n",
      "============================================================\n",
      "正在获取第 3 页...\n",
      "============================================================\n",
      "✓ 本页获取 20 条推文\n",
      "✓ 累计获取 60 条推文\n",
      "✓ 下一页游标: DAAHCgABG52efAb__8MLAAIAAAATMTk4OTgwMzEyMTI5MjI3MT...\n",
      "============================================================\n",
      "正在获取第 4 页...\n",
      "============================================================\n",
      "✓ 本页获取 20 条推文\n",
      "✓ 累计获取 80 条推文\n",
      "✓ 下一页游标: DAAHCgABG52efAb__68LAAIAAAATMTk4OTc4MDQ2MTc0MTAzNT...\n",
      "============================================================\n",
      "正在获取第 5 页...\n",
      "============================================================\n",
      "✓ 本页获取 20 条推文\n",
      "✓ 累计获取 100 条推文\n",
      "✓ 下一页游标: DAAHCgABG52efAb__5sLAAIAAAATMTk4OTc1MDI2ODkyMjA2OT...\n",
      "============================================================\n",
      "正在获取第 6 页...\n",
      "============================================================\n",
      "✓ 本页获取 20 条推文\n",
      "✓ 累计获取 120 条推文\n",
      "✓ 下一页游标: DAAHCgABG52efAb__4cLAAIAAAATMTk4OTcyNTA3ODM2NDI1MD...\n",
      "============================================================\n",
      "正在获取第 7 页...\n",
      "============================================================\n",
      "✓ 本页获取 20 条推文\n",
      "✓ 累计获取 140 条推文\n",
      "✓ 下一页游标: DAAHCgABG52efAb__3MLAAIAAAATMTk4OTY5ODY5MTk2ODQ5Nj...\n",
      "============================================================\n",
      "正在获取第 8 页...\n",
      "============================================================\n",
      "✓ 本页获取 20 条推文\n",
      "✓ 累计获取 160 条推文\n",
      "✓ 下一页游标: DAAHCgABG52efAb__18LAAIAAAATMTk4OTY2NzIyMDc4ODU2ND...\n",
      "============================================================\n",
      "正在获取第 9 页...\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "for user in a_kol_list[:10]:\n",
    "    user_id = get_user_rest_id(user)\n",
    "    tweets = fetch_user_tweets(user_id,max_pages=20)\n",
    "    filename = f'I:\\\\finance-agent\\\\X\\\\tweets_json\\\\{user}.json'\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        json.dump(tweets, f, indent=2, ensure_ascii=False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a1d08c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
